{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec6647b",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/CC_BY.png\"><br />\n",
    "\n",
    "Created by [Hannah Jacobs](http://hannahlangstonjacobs.com/) for the [2021 Text Analysis Pedagogy Institute](https://nkelber.github.io/tapi2021/book/intro.html).\n",
    "\n",
    "Adapted by [Nathan Kelber](http://nkelber.com) under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/)<br />\n",
    "For questions/comments/improvements, email nathan.kelber@ithaka.org.<br />\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d765b",
   "metadata": {},
   "source": [
    "# Creating an OCR Workflow (Post-Processing)\n",
    "\n",
    "These [notebooks](https://constellate.org/docs/key-terms/#jupyter-notebook) describe how to turn images and/or pdf documents into plain text using Tesseract [optical character recognition](https://constellate.org/docs/key-terms/#ocr). The goal of this notebook is to help users design a workflow for a research project.\n",
    "\n",
    "**Use Case:** For Learners (Detailed explanation, not ideal for researchers)\n",
    "\n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "**Completion time:** 90 minutes\n",
    "\n",
    "**Knowledge Required:** \n",
    "* Python Basics ([Start Python Basics I](../Python-basics/python-basics-1.ipynb))\n",
    "* [Optical Character Recognition Basics](./ocr-basics.ipynb)\n",
    "* [Creating an OCR Workflow (Pre-Processing)](./ocr-workflow-1.ipynb)\n",
    "\n",
    "**Knowledge Recommended:**\n",
    "\n",
    "**Data Format:** \n",
    "* image files (.jpg, .png)\n",
    "* document files (.pdf)\n",
    "* plain text (.txt)\n",
    "\n",
    "**Libraries Used:**\n",
    "* [Tesseract](https://tesseract-ocr.github.io/) for performing [optical character recognition](https://constellate.org/docs/key-terms/#ocr).\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "1. Run OCR on a large batch of prepared images\n",
    "2. Assess the degree of accuracy achieved in performing OCR\n",
    "3. Identify post-processing strategies for improving OCR accuracy\n",
    "\n",
    "**Research Pipeline:**\n",
    "\n",
    "1. Digitize documents\n",
    "2. **Optical Character Recognition**\n",
    "3. Tokenize your texts\n",
    "4. Perform analysis\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b368de",
   "metadata": {},
   "source": [
    "## \"Cleaning\" OCR (Post-Processing) Overview\n",
    "\n",
    "**This part of the process is often best performed with a combination of manual (human) and automated (computer) steps.** This is where you may be addressing not only errors in the OCR itself but also issues with the original printing, as we describe below with regard to hyphenated words at the end of lines. As with pre-processing, how complex you make iterations in this phase depends on your corpus and your resources:\n",
    "\n",
    "1. **Review the OCR output.** Take an initial look at the OCR text files. Sometimes even just a glance will give you a sense of how well the process has gone. If you see a lot of errors, return to the pre-processing questions and consider which steps you might take to improve the OCR output.\n",
    "\n",
    "\n",
    "2. **Run a spellchecker & calculate the quality of the OCR output.** Use a spellchecker to get a sense of just how accurate the OCR process may have been. Note that spellchecking here, as with spellchecking in software such as Word, is really looking for known and unknown words.\n",
    "\n",
    "\n",
    "3. **Use Python to check for and correct possible recurring & unique spelling errors.** These are errors that appear frequently and may be caused by the typescript, hyphenation at the end of lines, or other patterns that Tesseract repeatedly misinterprets. This step should focus on common words and avoid proper nouns (unless you have a full list of proper nouns to draw from). As with any automated step, it's possible that new errors will be introduced here. If there is a known and small quantity of proper nouns used in individual texts or across the corpus, and these are consistently \"read\" incorrectly by Tesseract, it may be possible to use Python to correct these.\n",
    "\n",
    "\n",
    "4. If your corpus is small enough and/or you have a team that can help you, **read through the corpus to manually check for and correct unique errors**. This may be a moment to correct proper nouns. If you have a team, it may be advisable to have texts read and corrected by multiple team members. It will be important that these team members have access to both inputs and outputs, and perhaps even lists of proper nouns, to be able to compare the original scans with the computer-readable versions. You may even want to set up a process whereby reviewers can flag words they are not sure about so that another reviewer can provide their opinion so that you and/or another project manager making a final decision on uncertain words.\n",
    "\n",
    "\n",
    "The above process could be broken down further to address smaller issues incrementally and iteratively. It may also be useful to break your corpus into units of analysis before or during this process to assist with cleaning. Let's download a sample, OCR it, and investigate the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d37ff07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T22:58:26.989734Z",
     "iopub.status.busy": "2024-06-27T22:58:26.989434Z",
     "iopub.status.idle": "2024-06-27T22:58:27.219431Z",
     "shell.execute_reply": "2024-06-27T22:58:27.218969Z",
     "shell.execute_reply.started": "2024-06-27T22:58:26.989715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Download sample PDF from On the Books\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "# Sample file to download\n",
    "url = 'https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/sample_01.pdf'\n",
    "\n",
    "# Check if a folder exists to hold pdfs. If not, create it.\n",
    "data_folder = Path('./data/')\n",
    "data_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Download the file\n",
    "path_url = Path(url)\n",
    "urllib.request.urlretrieve(url, f'{data_folder.as_posix()}/{path_url.name}')\n",
    "    \n",
    "## Success message\n",
    "print('PDF downloaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09769ce5",
   "metadata": {},
   "source": [
    "Now let's break the PDF down into individual images using the same method from our last lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2802f391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T22:58:27.220753Z",
     "iopub.status.busy": "2024-06-27T22:58:27.220312Z",
     "iopub.status.idle": "2024-06-27T22:58:30.031909Z",
     "shell.execute_reply": "2024-06-27T22:58:30.031364Z",
     "shell.execute_reply.started": "2024-06-27T22:58:27.220735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF converted successfully\n"
     ]
    }
   ],
   "source": [
    "### Convert a single PDF into a series of image files ###\n",
    "\n",
    "# Import pdf2image's convert_from_path module.\n",
    "from pdf2image import convert_from_path\n",
    "# Import pathlib's Path module.\n",
    "from pathlib import Path\n",
    "\n",
    "# Define where the images will be saved\n",
    "# Check if a folder exists to hold pdfs. If not, create it.\n",
    "input_folder = Path('./data/pdf_images/')\n",
    "input_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Get the PDF and convert to a group of PIL (Pillow) objects\n",
    "# This does NOT save the images as files.\n",
    "document_path = Path('./data/sample_01.pdf')\n",
    "PIL_objects = convert_from_path(document_path)\n",
    "\n",
    "# For each PIL image object:\n",
    "for page, image in enumerate(PIL_objects):\n",
    "\n",
    "    # Create a file name that includes the original file name, and\n",
    "    # a file number, as well as the file extension.\n",
    "    fileName = f'{input_folder.as_posix()}/image_{str(page)}.jpg'\n",
    "\n",
    "    # Save each PIL image object using the file name created above\n",
    "    # and declare the image's file format. (Try also PNG or TIFF.)\n",
    "    image.save(fileName, 'JPEG')\n",
    "\n",
    "# Success message\n",
    "print('PDF converted successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295713d",
   "metadata": {},
   "source": [
    "And finally, let's batch OCR all the pages, creating a single text file for each image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cd07d1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T22:58:30.033153Z",
     "iopub.status.busy": "2024-06-27T22:58:30.032730Z",
     "iopub.status.idle": "2024-06-27T22:59:06.654078Z",
     "shell.execute_reply": "2024-06-27T22:59:06.653594Z",
     "shell.execute_reply.started": "2024-06-27T22:58:30.033127Z"
    }
   },
   "outputs": [],
   "source": [
    "### Convert all the image files into text files ###\n",
    "import pytesseract\n",
    "\n",
    "#Import PIL's Image module.\n",
    "from PIL import Image\n",
    "\n",
    "# For each .jpg file in the input folder, do the following:\n",
    "for img in input_folder.rglob('*.jpg'):\n",
    "    # Open the input file and complete OCR\n",
    "    with open(f'{img}', 'rb') as f_image:\n",
    "        file = Image.open(f_image)\n",
    "        ocrText = pytesseract.image_to_string(file)\n",
    "    \n",
    "    # Create (or overwrite!) the output file and append the text\n",
    "    with open(f'{input_folder}/{img.stem}.txt', 'w') as f_text:\n",
    "        f_text.write(ocrText)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9e2ce",
   "metadata": {},
   "source": [
    "# Post-Processing Step-by-Step\n",
    "\n",
    "## Review the OCR output.\n",
    "\n",
    "Open your output text files and begin your review. Make sure to compare them with the original page images. What do you notice?\n",
    "\n",
    "## Check for misspellings & quality.\n",
    "\n",
    "Although it appears that this page has been entirely correctly OCR'ed, there are two issues that show up in this text file that we want to address in all of our OCR'ed files:\n",
    "\n",
    "1. The original printers **broke words at the end of some lines**. For example, `Dis-trict` might be broken up across two lines. How do we deal with this without removing words that *should* be hyphenated?\n",
    "2. **How would we know how accurate this simple script might be when applied to the entire volume, or to the entire corpus?** \n",
    "\n",
    "In addition to being hyphenated, `Dis-trict` may be misspelled as `Dis-triet` or `Dis-trism` in our output—is this just one instance, or does this error recur? If it's recurring, we can use Python to fix it across the corpus. This could be more efficient than having to read the entire OCR'ed corpus. A good starting point is to get a sense of just how accurate the OCR process has been, that is **check its readability**, before we start trying to identify and fix spelling errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ef531",
   "metadata": {},
   "source": [
    "**In the following scripts, we'll look at how to correct misspelling and check for OCR accuracy by generating a readability score.** During this process, we'll remove the hyphens at the end of lines to help us with spellchecking, but we may find that we introduce new issues for the spellcheck.\n",
    "\n",
    "To begin, there are a number of modules and libraries we need to import (or reimport) to extend Python's functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c1529a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T22:59:06.655581Z",
     "iopub.status.busy": "2024-06-27T22:59:06.655183Z",
     "iopub.status.idle": "2024-06-27T22:59:07.723799Z",
     "shell.execute_reply": "2024-06-27T22:59:07.723192Z",
     "shell.execute_reply.started": "2024-06-27T22:59:06.655565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in /opt/conda/lib/python3.11/site-packages (0.8.1)\n"
     ]
    }
   ],
   "source": [
    "### Install PySpellChecker ###\n",
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "656a0f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T22:59:07.725151Z",
     "iopub.status.busy": "2024-06-27T22:59:07.724778Z",
     "iopub.status.idle": "2024-06-27T22:59:08.012061Z",
     "shell.execute_reply": "2024-06-27T22:59:08.011627Z",
     "shell.execute_reply.started": "2024-06-27T22:59:07.725128Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to ./data/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the word_tokenize module from the nltk (\"Natural Language Processing Kit\") library.\n",
    "# NLTK is a powerful toolset we can use to manipulate and analyze text data.\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt', download_dir='./data/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4811d438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T22:59:08.013154Z",
     "iopub.status.busy": "2024-06-27T22:59:08.012741Z",
     "iopub.status.idle": "2024-06-27T22:59:08.016102Z",
     "shell.execute_reply": "2024-06-27T22:59:08.015701Z",
     "shell.execute_reply.started": "2024-06-27T22:59:08.013138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules & libraries imported. Ready for the next step.\n"
     ]
    }
   ],
   "source": [
    "# Import PyTesseract and PIL, an image processing library used by PyTesseract, to complete the OCR.\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Import re, a module that we can use to search text.\n",
    "import re\n",
    "\n",
    "# Import glob, a module that helps with file management.\n",
    "import glob\n",
    "\n",
    "# Import the SpellChecker module, which we'll use to look for likely misspelled words.\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# We'll also need the pandas library, which is a powerful toolset for managing data.\n",
    "# We'll learn more about pandas in the exploratory analysis modules.\n",
    "import pandas as pd\n",
    "\n",
    "# This statement confirms that the above code was run without issue.\n",
    "print(\"Modules & libraries imported. Ready for the next step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d80b8",
   "metadata": {},
   "source": [
    "Now we'll set up variables that we'll use to give Python information and structure information that Python returns. These include the location of the original image files and the place we want to store our OCR'ed text, as well as a [spellcheck dictionary](https://pypi.org/project/pyspellchecker/), which we'll extend to include North Carolina placenames, and a dataframe (essentially, an empty table) we'll use to structure readability information along with the OCR'ed text.\n",
    "\n",
    "*Note: The [spellchecker library](https://pypi.org/project/pyspellchecker/) we are using supports a limited number of Western languages. English is the default.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6c3393e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T22:59:08.016956Z",
     "iopub.status.busy": "2024-06-27T22:59:08.016668Z",
     "iopub.status.idle": "2024-06-27T22:59:08.322731Z",
     "shell.execute_reply": "2024-06-27T22:59:08.322270Z",
     "shell.execute_reply.started": "2024-06-27T22:59:08.016941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables created. Ready for the next step.\n"
     ]
    }
   ],
   "source": [
    "# Before we loop through each page, we'll augment our spellchecker \n",
    "# dictionary to include place names specific to North Carolina. \n",
    "# Our script for gathering these place names is available here: \n",
    "# https://github.com/UNC-Libraries-data/OnTheBooks/blob/master/examples/adjustment_recommendation/geonames.py\n",
    "\n",
    "# Load the spellchecker dictionary.\n",
    "# Replace the language attribute with another 2 letter code\n",
    "# to select another language. Options are: English - ‘en’, Spanish - ‘es’,\n",
    "# French - ‘fr’, Portuguese - ‘pt’, German - ‘de’, Russian - ‘ru’.\n",
    "\n",
    "spell = SpellChecker(language='en')\n",
    "\n",
    "# Add the place name words from the \"geonames.txt\" file to the \n",
    "# spellchecker dictionary.\n",
    "# Sample file to download\n",
    "url = 'https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/geonames.txt'\n",
    "\n",
    "# Download the file\n",
    "geonames_path = Path('./data/geonames.txt')\n",
    "urllib.request.urlretrieve(url, geonames_path)\n",
    "spell.word_frequency.load_text_file(geonames_path.as_posix())\n",
    "\n",
    "# This statement confirms that the above code was run without issue.\n",
    "print(\"Variables created. Ready for the next step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e5aaf",
   "metadata": {},
   "source": [
    "Here is what each column will hold:\n",
    "\n",
    "- **file_name**: The name for the corresponding image file. For now, this is the only information in the table that identifies where the rest of the information in each row comes from (which page).\n",
    "- **token_count**: The total number of tokens (words) found in each page.\n",
    "- **unknown_count**: The number of unknown (\"misspelled\") words found in each page.\n",
    "- **readability**: Think of this as the percentage of the page that was readable.\n",
    "- **unknown_words**: A list of tokens (words or in some cases characters) that were not listed in the spellchecker.\n",
    "- **text**: The OCR'ed text output from each page. The output here includes all <a href=\"https://en.wikipedia.org/wiki/Escape_character#JavaScript\" target=\"blank\">escape characters</a>, so it may look as if a lot of erronenous characters have been added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb9db3",
   "metadata": {},
   "source": [
    "Now we'll remove hyphens from the text, run the spellcheck script, and produce a dataframe (table) of information that will give us a sense of the accuracy of our OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b10c96c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T22:59:08.323832Z",
     "iopub.status.busy": "2024-06-27T22:59:08.323463Z",
     "iopub.status.idle": "2024-06-27T22:59:08.371234Z",
     "shell.execute_reply": "2024-06-27T22:59:08.370811Z",
     "shell.execute_reply.started": "2024-06-27T22:59:08.323816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pdf_images/image_7.txt checked for readability.\n",
      "data/pdf_images/image_3.txt checked for readability.\n",
      "data/pdf_images/image_9.txt checked for readability.\n",
      "data/pdf_images/image_5.txt checked for readability.\n",
      "data/pdf_images/image_4.txt checked for readability.\n",
      "data/pdf_images/image_8.txt checked for readability.\n",
      "data/pdf_images/image_0.txt checked for readability.\n",
      "data/pdf_images/image_1.txt checked for readability.\n",
      "data/pdf_images/image_2.txt checked for readability.\n",
      "data/pdf_images/image_6.txt checked for readability.\n"
     ]
    }
   ],
   "source": [
    "### Dictionary Test a Folder of .txt Files ###\n",
    "\n",
    "# We'll use Pandas to create a dataframe (a table) that can hold \n",
    "# information about an OCR'ed page and display it in a tabular format.\n",
    "# This dataframe will start out empty with only its column headers \n",
    "# defined. We'll add information to it one page at a time. So each\n",
    "# row will represent 1 page.\n",
    "\n",
    "df = pd.DataFrame(columns=[\"file_name\",\"token_count\",\"unknown_count\",\"readability\",\"unknown_words\",\"text\"])\n",
    "\n",
    "# Set the folder for the input images\n",
    "texts_folder = Path('./data/pdf_images/')\n",
    "\n",
    "for txt_file in texts_folder.iterdir():\n",
    "    if txt_file.suffix == '.txt':\n",
    "    \n",
    "        # Open each text file and read text into `ocrText`\n",
    "        with open(txt_file, 'r') as inputFile:\n",
    "            ocrText = inputFile.read()\n",
    "            \n",
    "        # Join hyphenated words that are split between lines by \n",
    "        # looking for a hyphen followed by a newline character: \"-\\n\"\n",
    "        # \"\\n\" is an \"escape character\" and represents the \n",
    "        # \"newline,\" a character that is usually invisible \n",
    "        # to human readers but that computers use to mark the \n",
    "        # end/beginning of a line. Each time you press the \n",
    "        # Enter/Return key on your keyboard, an invisible \"\\n\" \n",
    "        # is created to mark the beginning of a new line.\n",
    "        ocrText = ocrText.replace(\"-\\n\",\"\")\n",
    "        \n",
    "        # First, we'll use NLTK to \"tokenize\" text. \n",
    "                # \"Tokenize\" here means to take a page of our OCR'ed text,\n",
    "                # which Python is currently reading as one big glob of data,\n",
    "                # and separate each word out so that it can be read as an\n",
    "                # individual piece of data within a larger data structure \n",
    "                # (a list). This process also removes punctuation.\n",
    "        tokens = word_tokenize(ocrText)\n",
    "        \n",
    "        # Lowercase all tokens\n",
    "        tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "        \n",
    "        # Now we can get all of the words that don't match the \n",
    "        # spellchecker dictionary or our list of place names--\n",
    "        # these are the potential spelling errors.\n",
    "        unknown = spell.unknown(tokens)\n",
    "        \n",
    "        # Let's use a little math to find out how many potential \n",
    "        # spelling errors were identified. As part of this process, \n",
    "        # we'll create a \"readability\" score that will give us a \n",
    "        # percentage of how readable each file is--how much of the \n",
    "        # OCR'ed is \"correct.\"\n",
    "            \n",
    "        # If the list of unknown tokens (words) is greater than 0 \n",
    "        # (i.e. if the list is not empty):\n",
    "        if len(unknown) != 0:\n",
    "                \n",
    "                   # Following order of operations, here's what's happening \n",
    "                   # in the readability variable below:\n",
    "                   # 1. Divide the number of unknown tokens (len(unknown)) \n",
    "                        # by the total number of tokens on the page\n",
    "                        # (len(tokens)). Use \"float\" to specify that Python\n",
    "                        # returns a decimal number:\n",
    "                            # (float(len(unknown))/float(len(tokens))\n",
    "                   # 2. Multiply the number from step 1 by 100.\n",
    "                        # (float(len(unknown))/float(len(tokens)) * 100)\n",
    "                   # 3. Subtract the number from step 2 from 100.\n",
    "                        # 100 - (float(len(unknown))/float(len(tokens)) * 100)\n",
    "                   # 4. Round the number from step 3 to 2 decimal places\n",
    "                        # round(100 - (float(len(unknown))/float(len(tokens)) * 100), 2)\n",
    "                \n",
    "            readability = round(100 - (float(len(unknown))/float(len(tokens)) * 100), 2)\n",
    "            \n",
    "            # If the list of unknown tokens is empty (or equal to 0), then readability is 100!\n",
    "        else:\n",
    "            readability = 100\n",
    "        \n",
    "        # Let's create a record of the readability information \n",
    "        # for this page that we'll add to the dataframe. \n",
    "        # The following is a Python dictionary, another way of \n",
    "        # storing data. Each word or phrase to the left of the : is a\n",
    "        # \"key\" -- think of it as a column header. Each piece of \n",
    "        # information to the right is a \"value\" -- information \n",
    "        # written in a single cell below each header. \n",
    "    \n",
    "        df2 = pd.DataFrame({\n",
    "                \"file_name\" : txt_file.as_posix(),\n",
    "                \"token_count\" : len(tokens),\n",
    "                \"unknown_count\" : len(unknown),\n",
    "                \"readability\" : readability,\n",
    "                \"unknown_words\" : [unknown],\n",
    "                \"text\" : ocrText\n",
    "                })\n",
    "    \n",
    "        df = pd.concat([df, df2])\n",
    "    \n",
    "        # This statement lets us know if a page has been successfully \n",
    "        # checked for readability.\n",
    "        print(txt_file, \"checked for readability.\")\n",
    "    \n",
    "# This time, instead of creating individual .txt files for each page,\n",
    "# we're going to save all of the OCR'ed text and readability \n",
    "# information to a single .csv (\"comma separated value\") file. \n",
    "# We can view this file format as a table. Having everything stored \n",
    "# like this will help us with clean up and future analysis.\n",
    "df.to_csv(f'{texts_folder}/spellcheck_data.csv', header=True, index=False, sep=',')\n",
    "\n",
    "# We have the data stored in a file now, but we can also \n",
    "# preview it here:\n",
    "df\n",
    "\n",
    "# Delete the df variable in case we wish to run this script again\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d7ebd",
   "metadata": {},
   "source": [
    "# Correcting Errors\n",
    "\n",
    "Broadly speaking, we can break down errors into two categories: **unique** or **recurring**. We can use Python to address both types to an extent, but it's likely that some manual review will still need to be done to ensure the highest quality OCR. Whether and how much manual review can be done will depend on the project's resources.\n",
    "\n",
    "## Unique Errors\n",
    "\n",
    "There are at least **two ways to address unique computer-identified errors:**\n",
    "\n",
    "1. Since we produced a list of unknown words in our readability test, we could simply open each file in a text editor and use find-and-replace functionalities (Command + F or Control + F) to locate and replace instances of unique errors.\n",
    "\n",
    "2. We could use a little Python to find and replace these errors across the corpus. \n",
    "\n",
    "*Caveat: There may be instances where variant spellings are identified as \"unknown\" (misspelled) but are true representations of the word as it was originally printed. It may be necessary to check these misspellings against the scanned pages and decide whether or not to correct the text in the OCR output.*\n",
    "\n",
    "The following script runs through the entire sample output (and could be applied to an entire corpus) and checks for and replaces instances of a unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a4044de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T23:12:10.729177Z",
     "iopub.status.busy": "2024-06-27T23:12:10.728668Z",
     "iopub.status.idle": "2024-06-27T23:12:10.735470Z",
     "shell.execute_reply": "2024-06-27T23:12:10.735004Z",
     "shell.execute_reply.started": "2024-06-27T23:12:10.729158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All instances of diseretion replaced with discretion.\n"
     ]
    }
   ],
   "source": [
    "# Replacing unknown words with known words\n",
    "unknown_word = \"diseretion\"\n",
    "known_word = \"discretion\"\n",
    "\n",
    "# Import glob, a module that helps with file management.\n",
    "import glob\n",
    "\n",
    "# Identify the sample_output file path.\n",
    "# Remember that our readability output is also stored \n",
    "# in this file as a .csv. We don't want to change it, \n",
    "# so we'll use glob to look for only .txt files.\n",
    "file_list = glob.glob(\"./data/pdf_images/*.txt\")\n",
    "# Apply the following loop to one file at a time in filePath.\n",
    "\n",
    "# Read in a file's text\n",
    "for file in file_list:\n",
    "    file_path = Path(file)\n",
    "    with open(file_path) as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Correct the unknown word with a known word\n",
    "    corrected_text = text.replace(unknown_word, known_word)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(corrected_text)\n",
    "\n",
    "print(\"All instances of \" + unknown_word + \" replaced with \" + known_word + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd96d3",
   "metadata": {},
   "source": [
    "Check the output files for the unknown word to see if the word is still present. \n",
    "\n",
    "We've done this for one word at a time, but we could use the list of unknown words generated to create a script that runs through the list and corrects each instance all at once--rather than running the above script for each correction individually.\n",
    "\n",
    "## Recurring Errors & Changes\n",
    "\n",
    "There are several kinds of recurring errors:\n",
    "\n",
    "- Specific Words & Phrases (if a unique mispelling above is present consistently across the corpus, for example).\n",
    "- Word, Phrase, or Character Patterns (for example, a hyphen used to break up a word at the end of a line).\n",
    "\n",
    "We looked earlier at how to remove hyphens at the end of lines. To do this we replaced `-\\n` with nothing (\"\"). We saved that change to spellcheck csv, but we could have written that to the original text files. We could use the above script to make that change directly in the original output files, though it may be advisable to *keep the original text output files separate from the corrected versions in case you need to refer back.*\n",
    "\n",
    "We could also use the below script in combination with [regular expressions](https://en.wikipedia.org/wiki/Regular_expression) to correct issues that we know are recurring.\n",
    "\n",
    "**Be careful when attempting changes with regular expressions**--these always come with the risk of introducing new errors. To avoid as many as possible, make your regular expression as specific as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9d884da-666f-4b27-b6ca-c2d265ae882f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T23:51:38.648095Z",
     "iopub.status.busy": "2024-06-27T23:51:38.647790Z",
     "iopub.status.idle": "2024-06-27T23:51:38.656131Z",
     "shell.execute_reply": "2024-06-27T23:51:38.655688Z",
     "shell.execute_reply.started": "2024-06-27T23:51:38.648077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 match(es) found in  image_7.txt\n",
      "CH. 13-14 1955—SESSION LAWS\n",
      "\n",
      "have sufficient time to properly consider all complaints likely to arise on\n",
      "account of such revaluations: Now, therefore,\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. That the Board of County Commissioners in its discretion\n",
      "may extend the period during which it may sit in the year 1955 as a Board\n",
      "of Equalization and Review until such time as it has completed the work\n",
      "of hearing and determining complaints relating to revaluation; but said\n",
      "extension shall end on or before October 1st, 1955.\n",
      "\n",
      "Sec. 2. All laws and clauses of laws in conflict with this Act are here-\n",
      "by repealed.\n",
      "\n",
      "Sec. 3. This Act shall be in full force and effect from and after its\n",
      "ratification.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 4th day\n",
      "of February, 1955.\n",
      "\n",
      "S. B. 101 CHAPTER 14\n",
      "\n",
      "AN ACT TO AMEND CHAPTER 788 OF THE SESSION LAWS OF 1953\n",
      "SO AS TO APPOINT A MEMBER OF THE BOARD OF EDUCATION\n",
      "OF BRUNSWICK COUNTY TO SERVE OUT THE UNEXPIRED\n",
      "TERM OF RAY WALTON.\n",
      "\n",
      "WHEREAS, Ray Walton was named in Chapter 788 of the Session\n",
      "Laws of 1953 to serve on the Board of Education of Brunswick County for\n",
      "a term of two years; and\n",
      "\n",
      "WHEREAS, Ray Walton having been elected Senator from the Tenth\n",
      "Senatorial District to serve in the 1955 General Assembly resigned from\n",
      "his position as a member of the Board of Education of Brunswick\n",
      "County: Now, therefore,\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. Section 1 of Chapter 788 of the Session Laws of 1953 is here-\n",
      "by amended so as to provide that Thomas St. George is appointed a mem-\n",
      "ber of the Board of Education of Brunswick County to serve for the un-\n",
      "expired term of Ray Walton.\n",
      "\n",
      "Sec. 2. All laws and clauses of laws in conflict with this Act are here-\n",
      "by repealed.\n",
      "\n",
      "Sec. 3. This Act shall be in full force and effect from and after its\n",
      "ratification.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 4th day\n",
      "of February, 1955.\n",
      "\n",
      "B\n",
      "\f",
      "\n",
      "3 match(es) found in  image_3.txt\n",
      "CH. 5-6-T7 1955—SESSION LAWS\n",
      "\n",
      "H. B. 2 CHAPTER 5\n",
      "\n",
      "AN ACT TO REPEAL CHAPTER 501 OF THE SESSION LAWS OF 1953,\n",
      "RELATING TO COMMITTEE HEARINGS ON THE APPROPRIA-\n",
      "TIONS BILL.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. Chapter 501 of the Session Laws of 1953 is repealed.\n",
      "\n",
      "Sec. 2. All laws and clauses of laws in conflict with this Act are here-\n",
      "by repealed.\n",
      "\n",
      "Sec. 3. This Act shall be in full force and effect from and after its rati-\n",
      "fication.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 28th\n",
      "day of January, 1955.\n",
      "\n",
      "H. B. 18 CHAPTER 6\n",
      "\n",
      "AN ACT TO AMEND THE CHARTER OF THE CITY OF SALISBURY\n",
      "BY REQUIRING COUNCIL MEETINGS TO BE HELD AS OFTEN AS\n",
      "TWICE MONTHLY INSTEAD OF ONCE WEEKLY.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. Section 8 of Chapter 231 of the Private Laws of 1927, as\n",
      "amended by Chapter 178 of the Private Laws of 1929, be and the same is\n",
      "hereby further amended by striking out the first sentence appearing there-\n",
      "in and inserting in lieu thereof the following:\n",
      "\n",
      "“The Council shall fix suitable times for its regular meetings, which\n",
      "shall be as often as twice monthly.”\n",
      "\n",
      "Sec. 2. All laws and clauses of laws in conflict with this Act are here-\n",
      "by repealed.\n",
      "\n",
      "Sec. 3. This Act shall be in full force and effect from and after its\n",
      "ratification.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 28th\n",
      "day of January, 1955.\n",
      "\n",
      "S. B. 33 CHAPTER 17\n",
      "\n",
      "AN ACT TO AMEND ARTICLE 4 OF CHAPTER 15 OF THE GENERAL\n",
      "STATUTES SO AS TO PROVIDE FOR THE ISSUANCE OF SEARCH\n",
      "WARRANTS FOR NARCOTIC DRUGS.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. G. S. 15-25 is amended by inserting between the comma fol-\n",
      "lowing the word “premises” and the word “any” in line 5 of said Section\n",
      "the words and punctuation “any narcotic drugs as defined in Article 5 of\n",
      "Chapter 90 of the General Statutes,”. G. S. 15-25 is further amended by\n",
      "inserting between the word “such” and the word “stolen” in line 22 of said\n",
      "Section the words and punctuation ‘“narcotic drugs,”.\n",
      "\n",
      "Sec. 2. All laws and clauses of laws in conflict with this Act are hereby\n",
      "\n",
      "4\n",
      "\f",
      "\n",
      "No match found in  image_9.txt\n",
      "2 match(es) found in  image_5.txt\n",
      "CH. 9-10-11 1955—SESSION LAWS\n",
      "\n",
      "four per cent (4% ) of the sales price as confirmed by the board of county\n",
      "commissioners.\n",
      "\n",
      "Sec. 3. All laws and clauses of laws in conflict with this Act are hereby\n",
      "repealed.\n",
      "\n",
      "Sec. 4. This Act shall be in full force and effect from and after its\n",
      "ratification.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 3rd day\n",
      "of February, 1955. discretion\n",
      "\n",
      "H. B. 58 CHAPTER 10\n",
      "\n",
      "AN ACT TO AMEND G. S. 1-109, RELATING TO PROSECUTION\n",
      "BONDS, SO AS TO PLACE THE STATE ON THE SAME BASIS AS\n",
      "CITIES AND TOWNS WITH RESPECT TO EXEMPTION THERE-\n",
      "FROM.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. G. S. 1-109 is hereby amended by inserting the words ‘“the\n",
      "State of North Carolina or any of its agencies, commissions or institutions,\n",
      "or to” immediately following the word “to” and immediately preceding the\n",
      "word “counties”, in line 3 of paragraph 3, and by inserting the words “the\n",
      "State of North Carolina or any of its agencies, commissions or institutions,\n",
      "and” immediately following the word “that” and immediately preceding the\n",
      "word “counties” in line 4 of paragraph 3.\n",
      "\n",
      "Sec. 2. This Act shall apply to pending litigation, and all actions or\n",
      "proceedings heretofore instituted by the State of North Carolina or its\n",
      "agencies shall be valid as if the provisions of this Act had at all times been\n",
      "the law of the land.\n",
      "\n",
      "Sec. 3. All laws and clauses of laws in conflict with this Act are hereby\n",
      "repealed.\n",
      "\n",
      "Sec. 4. This Act shall become effective upon its ratification.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 3rd day\n",
      "of February, 1955.\n",
      "\n",
      "S. B. 22 CHAPTER 11\n",
      "\n",
      "AN ACT TO AMEND G. S. 153-38 SO AS TO PROVIDE FOR THE PAY-\n",
      "MENT OF THE EXPENSES BY GRANVILLE COUNTY OF THE\n",
      "COUNTY AUDITOR, THE CLERK TO THE BOARD OF COUNTY\n",
      "COMMISSIONERS, AND THE COUNTY ATTORNEY IN ATTEND-\n",
      "ING MEETINGS OF THE STATE ASSOCIATION OF COUNTY COM-\n",
      "MISSIONERS.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. G. S. 153-38 is amended by adding at the end thereof a new\n",
      "paragraph to read as follows:\n",
      "\n",
      "“In Granville County, the Board of County Commissioners is authorized,\n",
      "in its discretion, to pay the expenses of the County Auditor, the Clerk to\n",
      "\n",
      "6\n",
      "\n",
      "M\n",
      "\f",
      "\n",
      "2 match(es) found in  image_4.txt\n",
      "1955—SESSION LAWS CH. 7-8-9\n",
      "\n",
      "repealed.\n",
      "\n",
      "Sec. 3. This Act shall be in full force and effect from and after its rati-\n",
      "fication.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 3rd day\n",
      "of February, 1955.\n",
      "\n",
      "S. B. 38 CHAPTER 8\n",
      "\n",
      "AN ACT TO AMEND G. S. 7-274 SO AS TO AUTHORIZE THE CLERK\n",
      "OR DEPUTY CLERK OF THE GENERAL COUNTY COURT OF\n",
      "HALIFAX COUNTY TO ISSUE CRIMINAL WARRANTS.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. G. S. 7-274 is hereby amended by striking out the word\n",
      "“Halifax” as the same appears in line 13.\n",
      "\n",
      "Sec. 2. All laws and clauses of laws in conflict with this Act are hereby\n",
      "repealed.\n",
      "\n",
      "Sec. 3. This Act shall become effective upon ratification.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 3rd day\n",
      "of February, 1955.\n",
      "\n",
      "H. B. 28 CHAPTER 9\n",
      "\n",
      "AN ACT TO AUTHORIZE AND EMPOWER THE BOARD OF COMMIS-\n",
      "SIONERS OF STOKES COUNTY TO SELL AND CONVEY THE\n",
      "TRACT OF LAND AND BUILDINGS SITUATED THEREON FOR-\n",
      "MERLY USED BY THE COUNTY IN CONNECTION WITH THE\n",
      "OPERATION AND MAINTENANCE OF THE COUNTY HOME\n",
      "FARM.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. The Board of County Commissioners of Stokes County is\n",
      "hereby authorized and empowered to sell at public or private sale the entire\n",
      "tract of land and buildings situated thereon known as the County Home\n",
      "Farm or such part or parts thereof as in the discretion of the board will\n",
      "not be needed for public purposes. If the sale is made at public auction,\n",
      "notice of the sale shall be published once a week for two successive weeks\n",
      "in a newspaper of general circulation in the county. After any such public\n",
      "sale, the board of county commissioners is authorized to reject any bid\n",
      "which in the opinion of the board is not considered to be the fair market\n",
      "value of the partial or entire tract of land offered. If, after public auction,\n",
      "the board of county commissioners rejects the highest bid made, further\n",
      "public auctions may be held or the partial or entire tract of land may be\n",
      "sold privately for a higher price.\n",
      "\n",
      "Sec. 2. In carrying out the provisions of this Act the Board of County\n",
      "Commissioners of Stokes County may execute all necessary deeds and may\n",
      "employ an auction company to assist with subdividing and selling the\n",
      "property involved but shall not pay any company so employed more than\n",
      "\n",
      "5\n",
      "\f",
      "\n",
      "3 match(es) found in  image_8.txt\n",
      "1955—SESSION LAWS CH. 15-16-17\n",
      "\n",
      "H. B. 6 CHAPTER 15\n",
      "\n",
      "AN ACT TO REPEAL CHAPTER 522 OF THE SESSION LAWS OF 1953,\n",
      "RELATING TO COUNTY POLICEMEN OF MCDOWELL COUNTY.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. Chapter 522 of the Session Laws of 1953 is repealed.\n",
      "\n",
      "Sec. 2. All laws and clauses of laws in conflict with this Act are here-\n",
      "by repealed.\n",
      "\n",
      "Sec. 3. This Act shall be in full force and effect from and after its rati-\n",
      "fication.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 4th day\n",
      "of February, 1955.\n",
      "\n",
      "H. B. 15 CHAPTER 16\n",
      "\n",
      "AN ACT TO INCREASE THE MEMBERSHIP OF THE BOARD OF\n",
      "COUNTY COMMISSIONERS OF PERSON COUNTY FROM 3 TO 5,\n",
      "AND TO AMEND G. S. 153-5.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. That G. S. 153-5 is hereby amended by adding at the end\n",
      "thereof a paragraph reading as follows:\n",
      "\n",
      "“There shall be elected in Person County at the general election to be\n",
      "held in the year 1956 and every two years thereafter by the duly qualified\n",
      "voters thereof, a board of county commissioners composed of five persons\n",
      "who shall serve for a term of two years from the first Monday in Decem-\n",
      "ber after their election and until their successors are elected and quali-\n",
      "fied.”\n",
      "\n",
      "Sec. 2. All laws and clauses of laws in conflict with the provisions of\n",
      "this Act are hereby repealed.\n",
      "\n",
      "Sec. 3. This Act shall be in full force and effect from and after its\n",
      "ratification.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 4th day\n",
      "of February, 1955.\n",
      "\n",
      "H. B. 16 CHAPTER 17\n",
      "\n",
      "AN ACT TO AMEND CHAPTER 1056 OF THE GENERAL STATUTES SO\n",
      "AS TO CHANGE THE TIME FOR FILING STATE INCOME TAX\n",
      "RETURNS BY PERSONS OTHER THAN CORPORATIONS FROM\n",
      "THE FIFTEENTH DAY OF MARCH TO THE FIFTEENTH DAY OF\n",
      "APRIL IN EACH YEAR, AND TO CONFORM THE STATE LAW TO\n",
      "THE FEDERAL LAW AS TO THE TIME FOR FILING RETURNS.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. The first paragraph of G. S. 105-155 is hereby amended by\n",
      "rewriting said paragraph to read as follows:\n",
      "\n",
      "“Returns shall be in such form as the Commissioner of Revenue may\n",
      "from time to time prescribe, and shall be filed with the Commissioner at his\n",
      "\n",
      "9\n",
      "\f",
      "\n",
      "2 match(es) found in  image_0.txt\n",
      "SESSION LAWS\n",
      "\n",
      "OF THE\n",
      "\n",
      "STATE OF NORTH CAROLINA\n",
      "\n",
      "SESSION 1955\n",
      "\n",
      "S. B. 4 CHAPTER 1\n",
      "\n",
      "AN ACT TO AUTHORIZE THE BOARD OF TRUSTEES OF THE\n",
      "SOUTHERN PINES SCHOOL DISTRICT TO TRANSFER CERTAIN\n",
      "FUNDS FROM ITS DEBT SERVICE ACCOUNT TO ITS CAPITAL\n",
      "OUTLAY OR CURRENT EXPENSE ACCOUNTS, OR TO BOTH\n",
      "SUCH ACCOUNTS.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. The Board of Trustees of the Southern Pines School Dis-\n",
      "trict is hereby authorized and empowered to transfer all surplus funds held\n",
      "by it in its debt service account on the date of the ratification of this Act\n",
      "or on July 1, 1955, to its capital outlay account or current expense account,\n",
      "or to both such accounts, and to use said funds for capital outlay or current\n",
      "expense purposes, or both, including the construction of school buildings.\n",
      "\n",
      "Sec. 2. All laws and clauses of laws in conflict with this Act are hereby\n",
      "repealed.\n",
      "\n",
      "Sec. 3. This Act shall become effective on and after its ratification.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 14th\n",
      "day of January, 1955.\n",
      "\n",
      "H. B. 13 CHAPTER 2\n",
      "\n",
      "AN ACT TO PERMIT THE BOARD OF COMMISSIONERS OF\n",
      "CATAWBA COUNTY TO MAKE APPROPRIATIONS FOR BUILDING\n",
      "WATER LINES, SEWER LINES OR EITHER OF THEM, FROM THE\n",
      "CORPORATE LIMITS OF MUNICIPALITIES TO COMMUNITIES IN\n",
      "THE COUNTY.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. The Board of County Commissioners of Catawba County is\n",
      "hereby authorized and empowered in its discretion to expend out of non-\n",
      "tax funds available to said board such amount or amounts as it may deem\n",
      "wise, not exceeding in the aggregate the sum of one hundred and twenty-\n",
      "\n",
      "1\n",
      "\f",
      "\n",
      "1 match(es) found in  image_1.txt\n",
      "CH. 28 1955—SESSION LAWS\n",
      "\n",
      "five thousand dollars ($125,000.00), to be used in such amounts in the dis-\n",
      "cretion of said board of county commissioners for the purpose of acquir-\n",
      "ing easements for water and sewer lines, or either of them, and for the\n",
      "purpose of laying and constructing water and sewer lines or either of them\n",
      "from the corporate limits of municipalities located in Catawba County to\n",
      "communities located within said county, but outside of the corporate limits\n",
      "of municipalities, said water and sewer lines, or either of them, shall be\n",
      "constructed and laid and said easements therefor shall be acquired, for the\n",
      "purpose of promoting the general welfare of said county and the expense\n",
      "of laying and construction of said lines and acquiring said easements is\n",
      "hereby declared to be expenditures for public purposes.\n",
      "\n",
      "Sec. 2. All laws and clauses of laws in conflict with this Act are hereby\n",
      "repealed.\n",
      "\n",
      "Sec. 3. This Act shall be in full force and effect from and after its\n",
      "ratification.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 14th\n",
      "day of January, 1955.\n",
      "\n",
      "S. B. 13 CHAPTER 3\n",
      "\n",
      "AN ACT TO AMEND THE ELECTION LAW HERETOFORE PROVIDED\n",
      "FOR THE TOWN OF CONETOE, IN EDGECOMBE COUNTY, AND\n",
      "TO FIX THE DATES OF ELECTIONS FOR SAID TOWN.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. Amend Section 2 of Chapter 673 of the Session Laws of 1953\n",
      "by striking out the following: “1953\"”, appearing in the first line of said\n",
      "Section 2, and by inserting in lieu thereof the following: “1955”.\n",
      "\n",
      "Sec. 2. Amend Section 3 of Chapter 673 of the Session Laws of 1953\n",
      "by striking out the figures “1953”, as the same appear in the eighth line of\n",
      "said Section 3, and by inserting in lieu thereof the figures “1955”.\n",
      "\n",
      "Sec. 3. Amend Section 4 of Chapter 673 of the Session Laws of 1953 by\n",
      "striking out the figures “1955”, as the same appear in the first line of said\n",
      "Section 4, and by inserting in lieu thereof the figures “1957”.\n",
      "\n",
      "Further amend said Section 4 of Chapter 673 of the Session Laws of\n",
      "1953 by striking out the figures “1953”, as the same appear in the tenth\n",
      "line of said Section 4, and by inserting in lieu thereof the figures “1955”.\n",
      "\n",
      "Sec. 4. All laws and clauses of laws in conflict with this Act are hereby\n",
      "repealed.\n",
      "\n",
      "Sec. 5. This Act shall be in full force and effect from and after its rati-\n",
      "fication.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 14th day\n",
      "of January, 1955.\n",
      "\f",
      "\n",
      "1 match(es) found in  image_2.txt\n",
      "1955—SESSION LAWS CH.4\n",
      "\n",
      "H. B. 34 CHAPTER 4\n",
      "\n",
      "AN ACT TO PROVIDE THAT THE OFFICE OF SOLICITOR OF THE\n",
      "RECORDER’S COURT OF FRANKLIN COUNTY BE AN ELECTIVE\n",
      "OFFICE. '\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. That Section 6 of Chapter 12, Session Laws of 1951 is here-\n",
      "by repealed.\n",
      "\n",
      "Sec. 2. That G. S. 7-235 is hereby amended by adding at the end there-\n",
      "of the following:\n",
      "\n",
      "“Provided that as of February 1, 1955, the office of prosecuting attor-\n",
      "ney of the Recorder’s Court of Franklin County, denominated solicitor,\n",
      "shall be an elective office. The first solicitor shall be elected by the Board\n",
      "of Commissioners of Franklin County on or before February 1, 1955, and\n",
      "shall hold his office under said appointment until the first Monday in De-\n",
      "cember, 1956. At the primary and general elections to be held in the year\n",
      "1956 and biennially thereafter, the Solicitor of the Recorder’s Court of\n",
      "Franklin County shall be nominated and elected in the same manner and\n",
      "at the same time as is now or may hereafter be provided by law for the\n",
      "nomination and election of the elective officers of the county; the term of\n",
      "office of said Solicitor shall begin on the first Monday in December follow-\n",
      "ing the biennial general election at which he shall have been elected and\n",
      "shall extend to the first Monday in December following the next ensuing\n",
      "biennial general election. In the event of a vacancy in the office of Solicitor,\n",
      "either by death, resignation, failure to qualify, or otherwise, the Board of\n",
      "Commissioners of Franklin County shall fill such vacancy by appointment\n",
      "and the person so appointed shall serve until the first Monday in December\n",
      "following the next biennial general election. The salary of said Solicitor\n",
      "shall be two thousand four hundred dollars ($2400.00) per year and shall\n",
      "be paid in equal monthly installments from the General Fund of the county.\n",
      "The said Solicitor shall, at the time of his appointment or nomination and\n",
      "election, be a qualified elector of Franklin County and a licensed attorney\n",
      "at law, and before entering upon the duties of his office shall take and sub-\n",
      "scribe an oath substantially in the form required of State solicitors by\n",
      "Section 11-11 of the General Statutes of North Carolina, and said oath shall\n",
      "be recorded by the Clerk of the Superior Court of Franklin County.”\n",
      "\n",
      "Sec. 3. All laws and clauses of laws in conflict with the provisions of\n",
      "this Act are hereby repealed.\n",
      "\n",
      "Seec. 4. This Act shall be in full force and effect from and after its rati-\n",
      "fication.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 26th day\n",
      "of January, 1955.\n",
      "\f",
      "\n",
      "1 match(es) found in  image_6.txt\n",
      "1955—SESSION LAWS Ca 11-12:13\n",
      "\n",
      "the Board of County Commissioners, and the County Attorney in attend-\n",
      "ing meetings of the State Association of County Commissioners.”\n",
      "\n",
      "Sec. 2. All action heretofore taken by the Board of County Commission-\n",
      "ers of Granville County in paying the expenses of the officials named in\n",
      "Section 1 of this Act in attending meetings of the State Association of\n",
      "County Commissioners is hereby validated, ratified, and confirmed.\n",
      "\n",
      "Sec. 3. All laws and clauses of laws in conflict with this Act are hereby\n",
      "repealed.\n",
      "\n",
      "Sec. 4. This Act shall be in full force and effect from and after its rati-\n",
      "fication.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 4th day\n",
      "of February, 1955.\n",
      "\n",
      "S. B. 34 CHAPTER 12\n",
      "\n",
      "AN ACT TO AMEND CHAPTER 465 OF THE SESSION LAWS OF 1949\n",
      "TO AUTHORIZE THE BOARD OF COUNTY COMMISSIONERS OF\n",
      "ROWAN COUNTY IN ITS DISCRETION TO ADD THE DUTIES\n",
      "AND POWERS OF COUNTY TAX SUPERVISOR TO THOSE NOW\n",
      "BEING PERFORMED BY THE COUNTY TAX COLLECTOR.\n",
      "\n",
      "The General Assembly of North Carolina do enact:\n",
      "\n",
      "Section 1. Section 1 of Chapter 465 of the Session Laws of 1949 is\n",
      "hereby amended by rewriting Section 4 thereof to read as follows: “Sec. 4.\n",
      "The Board of County Commissioners of Rowan County may, in its discre-\n",
      "tion, add the duties and powers of County Tax Supervisor to those now\n",
      "being performed by the County Auditor or by the County Tax Collector\n",
      "and, in such event, may pay such County Auditor or County Tax Collector\n",
      "such additional compensation for such services as, in its discretion, it may\n",
      "deem appropriate.”\n",
      "\n",
      "Seec. 2. All laws and clauses of laws in conflict with this Act are here-\n",
      "by repealed.\n",
      "\n",
      "Sec. 3. This Act shall be in full force and effect from and after its rati-\n",
      "fication.\n",
      "\n",
      "In the General Assembly read three times and ratified, this the 4th\n",
      "day of February, 1955.\n",
      "\n",
      "S. B. 35 CHAPTER 13\n",
      "\n",
      "AN ACT AUTHORIZING THE BOARD OF COUNTY COMMISSIONERS\n",
      "OF ROWAN COUNTY TO EXTEND THE PERIOD DURING WHICH\n",
      "IT MAY SIT IN 1955 AS A BOARD OF EQUALIZATION AND RE-\n",
      "VIEW.\n",
      "\n",
      "WHEREAS, the Board of County Commissioners of Rowan County are\n",
      "in the process of revaluing taxable property in Rowan County; and\n",
      "\n",
      "WHEREAS, the revaluation was not completed on January 1st, 1955\n",
      "the day upon which tax listing began; and\n",
      "\n",
      "WHEREAS, the said County Commissioners, acting as a Board of\n",
      "Equalization and Review from March 21st to April 11th, 1955, will not\n",
      "\n",
      "7\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the regular expressions module (re), \n",
    "# which helps us use regex in Python.\n",
    "import re\n",
    "\n",
    "# Import glob, a module that helps with file management.\n",
    "import glob\n",
    "\n",
    "# Identify the sample_output file path.\n",
    "# Remember that our readability output is also stored \n",
    "# in this file as a .csv. We don't want to change it, \n",
    "# so we'll use glob to look for only .txt files.\n",
    "file_list = glob.glob(\"./data/pdf_images/*.txt\")\n",
    "\n",
    "# Save the pattern for a chapter header (even pages) that we \n",
    "# want to search each page for. We've added \"^\" to our regular \n",
    "# expressions to be extra sure that Python searches only at the \n",
    "# beginning of each file.\n",
    "regex_search = re.compile(\"\\n\\nThe General Assembly.*?t:\\n\\n\")\n",
    "\n",
    "# Save the text that we want to use to correct the OCR output.\n",
    "replacement = \"\\n\\nThe General Assembly of North Carolina do enact:\\n\\n\"\n",
    "\n",
    "# Apply the following loop to one file at a time in filePath.\n",
    "for file in file_list:\n",
    "    file_path = Path(file)\n",
    "    \n",
    "    corrected_text = None\n",
    "    with file_path.open() as f:\n",
    "        text = f.read()\n",
    "        if re.search(regex_search, text):\n",
    "            \n",
    "            # Create a corrected version\n",
    "            corrected_text = re.subn(regex_search, replacement, text)\n",
    "            print(corrected_text[1], 'match(es) found in ', file_path.name)\n",
    "        else:\n",
    "            print('No match found in ', file_path.name)\n",
    "\n",
    "    # Write the corrected text to the file\n",
    "    if corrected_text != None:\n",
    "        new_file = file_path.stem + '_corrected.txt'\n",
    "        with open(new_file, 'w') as f:\n",
    "            f.write(corrected_text[0])\n",
    "        \n",
    "            \n",
    "    #         # Substitute the regex_search for the replacement phrase\n",
    "    #         # and write the updated contents of inFile to outFile.\n",
    "    #         outFile.write(re.sub(regex_search, replacement, inFile))\n",
    "        \n",
    "    #     # If neither the regex search is not found,\n",
    "    #     else:\n",
    "            \n",
    "    #         # print a statement to let us know that no matches were found.\n",
    "    #         print(outFileName, \"No match found.\")\n",
    "            \n",
    "    #         # And write all of the contents from the inFile to the outFile.\n",
    "    #         outFile.write(inFile)\n",
    "        \n",
    "    # # Create a file name for a new output file.\n",
    "    \n",
    "    # # First, get the existing file name \n",
    "    # # (e.g. \"sessionlawsresol1955nort_0066.txt\")\n",
    "    # # & create a new name for the output file\n",
    "    # outFileName = file.replace(\".txt\", \"_corrected.txt\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # # Create and open a new \"outFile\" to save our results to.\n",
    "    # # \"w\" tells Python that we plan to write to this file.\n",
    "    # outFile = open(outFileName, \"w\")\n",
    "    \n",
    "    # # Open a file in \"read\" (r) mode.\n",
    "    # inFile = open(file, \"r\")\n",
    "    \n",
    "    # # Read in the contents of that file.\n",
    "    # inFile = inFile.read()\n",
    "    \n",
    "    # # Search inFile for the the regular expression.\n",
    "    # if re.search(regex_search, inFile):\n",
    "        \n",
    "    #     # If the regex search is found,\n",
    "    #     # print a statement to let us know that there is a match.\n",
    "    #     print(outFileName, \"Match found.\")\n",
    "        \n",
    "    #     # Substitute the regex_search for the replacement phrase\n",
    "    #     # and write the updated contents of inFile to outFile.\n",
    "    #     outFile.write(re.sub(regex_search, replacement, inFile))\n",
    "    \n",
    "    # # If neither the regex search is not found,\n",
    "    # else:\n",
    "        \n",
    "    #     # print a statement to let us know that no matches were found.\n",
    "    #     print(outFileName, \"No match found.\")\n",
    "        \n",
    "    #     # And write all of the contents from the inFile to the outFile.\n",
    "    #     outFile.write(inFile)\n",
    "    \n",
    "    # # Close the current outFile and move to the next file.\n",
    "    # outFile.close()\n",
    "    \n",
    "# The loop will finish when Python has gone through all files in \n",
    "# the sample_output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad379fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T23:15:11.279088Z",
     "iopub.status.busy": "2024-06-27T23:15:11.278712Z",
     "iopub.status.idle": "2024-06-27T23:15:11.368616Z",
     "shell.execute_reply": "2024-06-27T23:15:11.368109Z",
     "shell.execute_reply.started": "2024-06-27T23:15:11.279069Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/pdf_images/image_7_corrected.txt Match found.\n",
      "./data/pdf_images/image_3_corrected.txt Match found.\n",
      "./data/pdf_images/image_9_corrected.txt No match found.\n",
      "./data/pdf_images/image_5_corrected.txt Match found.\n",
      "./data/pdf_images/image_4_corrected.txt Match found.\n",
      "./data/pdf_images/image_8_corrected.txt Match found.\n",
      "./data/pdf_images/image_0_corrected.txt Match found.\n",
      "./data/pdf_images/image_1_corrected.txt Match found.\n",
      "./data/pdf_images/image_2_corrected.txt Match found.\n",
      "./data/pdf_images/image_6_corrected.txt Match found.\n"
     ]
    }
   ],
   "source": [
    "# Import the regular expressions module (re), \n",
    "# which helps us use regex in Python.\n",
    "import re\n",
    "\n",
    "# Import glob, a module that helps with file management.\n",
    "import glob\n",
    "\n",
    "# Identify the sample_output file path.\n",
    "# Remember that our readability output is also stored \n",
    "# in this file as a .csv. We don't want to change it, \n",
    "# so we'll use glob to look for only .txt files.\n",
    "filePath = glob.glob(\"./data/pdf_images/*.txt\")\n",
    "\n",
    "# Save the pattern for a chapter header (even pages) that we \n",
    "# want to search each page for. We've added \"^\" to our regular \n",
    "# expressions to be extra sure that Python searches only at the \n",
    "# beginning of each file.\n",
    "regex_search = re.compile(\"\\n\\nThe General Assembly.*?t:\\n\\n\")\n",
    "\n",
    "# Save the text that we want to use to correct the OCR output.\n",
    "replacement = \"\\n\\nThe General Assembly of North Carolina do enact:\\n\\n\"\n",
    "\n",
    "# Apply the following loop to one file at a time in filePath.\n",
    "for file in filePath:\n",
    "    \n",
    "    # Create a file name for a new output file.\n",
    "    \n",
    "    # First, get the existing file name \n",
    "    # (e.g. \"sessionlawsresol1955nort_0066.txt\")\n",
    "    # & create a new name for the output file\n",
    "    outFileName = file.replace(\".txt\", \"_corrected.txt\")\n",
    "\n",
    "    # Create and open a new \"outFile\" to save our results to.\n",
    "    # \"w\" tells Python that we plan to write to this file.\n",
    "    outFile = open(outFileName, \"w\")\n",
    "    \n",
    "    # Open a file in \"read\" (r) mode.\n",
    "    inFile = open(file, \"r\")\n",
    "    \n",
    "    # Read in the contents of that file.\n",
    "    inFile = inFile.read()\n",
    "    \n",
    "    # Search inFile for the the regular expression.\n",
    "    if re.search(regex_search, inFile):\n",
    "        \n",
    "        # If the regex search is found,\n",
    "        # print a statement to let us know that there is a match.\n",
    "        print(outFileName, \"Match found.\")\n",
    "        \n",
    "        # Substitute the regex_search for the replacement phrase\n",
    "        # and write the updated contents of inFile to outFile.\n",
    "        outFile.write(re.sub(regex_search, replacement, inFile))\n",
    "    \n",
    "    # If neither the regex search is not found,\n",
    "    else:\n",
    "        \n",
    "        # print a statement to let us know that no matches were found.\n",
    "        print(outFileName, \"No match found.\")\n",
    "        \n",
    "        # And write all of the contents from the inFile to the outFile.\n",
    "        outFile.write(inFile)\n",
    "    \n",
    "    # Close the current outFile and move to the next file.\n",
    "    outFile.close()\n",
    "    \n",
    "# The loop will finish when Python has gone through all files in \n",
    "# the sample_output folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9bbe58",
   "metadata": {},
   "source": [
    "# Concatenate all the text files into one\n",
    "If we are happy with our outputs, then we can stitch all the text files into a single text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec84ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the folder for the input texts\n",
    "texts_folder = Path('./data/pdf_images/')\n",
    "\n",
    "# Set output filename and create file\n",
    "full_text = Path('./data/full.txt')\n",
    "full_text.touch()\n",
    "\n",
    "for txt in texts_folder.rglob('*corrected.txt'):\n",
    "    with open(txt, 'r') as f_in:\n",
    "        fileText = f_in.read()\n",
    "        with open(full_text, 'a') as f_out:\n",
    "            f_out.write(fileText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908b427",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "Here's [the first 50 pages of an edition of Moby Dick from 1922](https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/moby_dick.pdf). Can you OCR all the pages and then generate a list of errors based on dictionary analysis? How about replacing some of the text with errors?\n",
    "\n",
    "`https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/moby_dick.pdf`\n",
    "\n",
    "You'll need to start by either using `urllib.request` to download the materials to the Constellate environment or by downloading the document to your local machine and uploading it to Constellate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
