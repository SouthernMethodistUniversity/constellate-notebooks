{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3837c7c-ff78-4782-aa8e-1807157ab977",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/CC_BY.png\"><br />\n",
    "\n",
    "Created by [Nathan Kelber](http://nkelber.com) under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/)<br />\n",
    "For questions/comments/improvements, email nathan.kelber@ithaka.org.<br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622275e5-4266-42e2-be28-71448c15da7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Language Models 3: ðŸ¤— Hugging Face with RAG\n",
    "\n",
    "**Description:** \n",
    "\n",
    "\n",
    "**Use Case:** For Learners (Detailed explanation, not ideal for researchers)\n",
    "\n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "**Completion Time:** 75 minutes\n",
    "\n",
    "**Knowledge Required:** \n",
    "* Python Basics\n",
    "* Pandas Basics\n",
    "\n",
    "**Knowledge Recommended:** \n",
    "* Python Intermediate\n",
    "* Pandas Intermediate\n",
    "\n",
    "**Data Format:** None\n",
    "\n",
    "**Libraries Used:** \n",
    "* [ðŸ¤— Transformers](https://huggingface.co/docs/transformers/index)- provides APIs and tools to easily download and train pretrained models\n",
    "* [Pytorch](https://pytorch.org/)- a popular machine learning framework\n",
    "* [Llama_index](https://docs.llamaindex.ai/en/stable/)- helps index our documents\n",
    "\n",
    "**Research Pipeline:** None\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7fddd-96e8-4acd-a9bb-1aed807d4a8e",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63e6c8f-870d-462e-bd2d-7b75a4f33f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install transformers and llama-index libraries\n",
    "!pip install transformers\n",
    "!pip install llama-index\n",
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1ca27-79c4-4297-9d14-72e599c08efd",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51faa807-50e8-4cad-9511-7d9896993845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import login\n",
    "from huggingface_hub import InferenceClient\n",
    "import urllib.request\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f84a8-64cd-4b29-9a75-730d01b4baf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can grab a particular dataset builder\n",
    "# without downloading the whole dataset\n",
    "# That allows us to preview its description and features first\n",
    "# Dataset https://huggingface.co/datasets/wikitext\n",
    "ds_builder = load_dataset_builder(\"wikitext\", 'wikitext-103-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426e1d5-c7a1-4ebd-abcd-ad6f2abbce85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use .info.description to retrieve the description\n",
    "ds_builder.info.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688398d-e133-44a5-9ad3-6fe678eac927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use .info.features to retrieve the features\n",
    "ds_builder.info.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006c8ce-14cd-4351-bfcc-1418f5d040b7",
   "metadata": {},
   "source": [
    "# Download Documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52cb964-c4d0-436c-a68b-00a8ae55ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = Path.cwd() / \"documents\"\n",
    "dir_path.mkdir(exist_ok=True)\n",
    "\n",
    "files ={\n",
    "    \"jupyter-ai-documentation.txt\" : 'https://jupyter-ai.readthedocs.io/en/latest/_sources/users/index.md.txt',\n",
    "    \"llama-3.1b-405.txt\" : 'https://raw.githubusercontent.com/meta-llama/llama-models/main/models/llama3_1/MODEL_CARD.md',\n",
    "    \"mistral-large-instruct-2407.txt\" : 'https://huggingface.co/mistralai/Mistral-Large-Instruct-2407/resolve/main/README.md'\n",
    "}\n",
    "    \n",
    "for file_name, url in files.items():\n",
    "    urllib.request.urlretrieve(url, f'./documents/{file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d278f21-7ac2-4f61-8c67-1a68d1efddbe",
   "metadata": {},
   "source": [
    "# Simple Directory Reader\n",
    "\n",
    "The simple directory reader will gather up all the files in a directory and turn them into a list of document objects. It can parse many kinds of files including pdfs, text files, markdown files, etc. It will intelligently select the right reader for the right file, and it will process them differently. For example, a text file is treated as a single document whereas a markdown file is broken down by headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d28a58-10bb-46cb-a376-df5b499d0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect documents into a list\n",
    "docs = SimpleDirectoryReader(\"documents\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef3f72-8319-424a-ba29-0631ac19363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb62301e-168a-42f2-99eb-ea499f37d590",
   "metadata": {},
   "source": [
    "# Embedding Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e642e66-013e-47a3-95e4-9019e9226374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a Hugging Face embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "Settings.llm = None\n",
    "Settings.chunk_size = 256\n",
    "Settings.chunk_overlap = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b2a22-2ef1-4333-8326-8d743f0eded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector database from doc\n",
    "index = VectorStoreIndex.from_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b07608-6902-40c9-bf4d-f1b9cec87475",
   "metadata": {},
   "source": [
    "# Search function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d849a-5bdc-42f9-8597-dad18706482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents to retrieve\n",
    "top_k = 3\n",
    "\n",
    "# Retriever configuration\n",
    "retriever = VectorIndexRetriever(\n",
    "    index = index,\n",
    "    similarity_top_k=top_k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c98bec-a176-4a2b-9b2d-d9293d913f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff96744-3707-474f-95cd-9ef6cffb1751",
   "metadata": {},
   "source": [
    "# Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed761d79-5175-4cbd-94f2-28eaff875b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "query = 'What providers does Jupyter AI support?'\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04432584-8ae2-4d25-aed9-422955582c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a context string from response\n",
    "context = \"Context:\\n\"\n",
    "for i in range(top_k):\n",
    "    context = context + response.source_nodes[i].text + \"\\n\\n\"\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601febf0-beb2-4176-9fe9-fcfaa1700d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragless_prompt = f\"\"\"\n",
    "[INST] ResearchBuddy, a virtual consultant for research tasks communicates in clear, accessible language helping answer technical questions on documentation.\n",
    "\n",
    "Please respond to the following comment.\n",
    "{query}\n",
    "\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe17744-9711-468d-bb0e-810ba2828768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG prompt with the context\n",
    "ragful_prompt = ragless_prompt + context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c2b36-f68c-4e4a-90c8-bb241e93cdd5",
   "metadata": {},
   "source": [
    "### Pass the prompt to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84dd995-0223-4ae6-ba8c-7d788e451d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Log in using an access token\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b83417a-0f48-4429-a676-37c837846b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model\n",
    "client = InferenceClient(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925fd57c-91e8-4fd1-9ead-950ebe370580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the model without context\n",
    "\n",
    "for message in client.chat_completion(\n",
    "\tmessages=[{\"role\": \"user\", \"content\": ragless_prompt}],\n",
    "\tmax_tokens=500,\n",
    "\tstream=True,\n",
    "):\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ea8a5-e6d2-427a-ab27-d93fdde93f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the model with RAG context\n",
    "\n",
    "for message in client.chat_completion(\n",
    "\tmessages=[{\"role\": \"user\", \"content\": ragful_prompt}],\n",
    "\tmax_tokens=500,\n",
    "\tstream=True,\n",
    "):\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
